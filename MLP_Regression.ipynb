{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('C:/Users/JW/Desktop/khl/data/train_set.csv')\n",
    "test_set = pd.read_csv('C:/Users/JW/Desktop/khl/data/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.iloc[:,:12]\n",
    "y_train = train_set.iloc[:,12]\n",
    "X_test = test_set.iloc[:,:12]\n",
    "y_test = test_set.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temp</th>\n",
       "      <th>TSI</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>altitude</th>\n",
       "      <th>solar_rad</th>\n",
       "      <th>High_solar_rad</th>\n",
       "      <th>casi</th>\n",
       "      <th>humidity</th>\n",
       "      <th>rain</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>rail_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.3</td>\n",
       "      <td>1348.466876</td>\n",
       "      <td>293.613375</td>\n",
       "      <td>-19.933239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.1</td>\n",
       "      <td>1348.466876</td>\n",
       "      <td>295.400987</td>\n",
       "      <td>-21.775745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.9</td>\n",
       "      <td>1348.466876</td>\n",
       "      <td>297.243863</td>\n",
       "      <td>-23.590784</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.6</td>\n",
       "      <td>1348.466876</td>\n",
       "      <td>299.147076</td>\n",
       "      <td>-25.375575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.4</td>\n",
       "      <td>1348.466876</td>\n",
       "      <td>301.115874</td>\n",
       "      <td>-27.127102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_temp          TSI     azimuth   altitude  solar_rad  High_solar_rad  \\\n",
       "0      22.3  1348.466876  293.613375 -19.933239          0               0   \n",
       "1      22.1  1348.466876  295.400987 -21.775745          0               0   \n",
       "2      21.9  1348.466876  297.243863 -23.590784          0               0   \n",
       "3      21.6  1348.466876  299.147076 -25.375575          0               0   \n",
       "4      21.4  1348.466876  301.115874 -27.127102          0               0   \n",
       "\n",
       "   casi  humidity  rain  wind_speed  wind_direction  rail_direction  \n",
       "0     0        57   0.0         222            0.18               0  \n",
       "1     0        59   0.0         200            0.40               0  \n",
       "2     0        61   0.0         245            0.19               0  \n",
       "3     0        61   0.0         230            0.36               0  \n",
       "4     0        63   0.0         270            0.28               0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "y_test = np.asarray(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, input_shape=(12,), activation='sigmoid'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JW\\Desktop\\khl\\venv\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 10)                130       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 100)               1100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,450\n",
      "Trainable params: 1,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 1246.0321 - mse: 1246.0321\n",
      "Epoch 2/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 1134.6375 - mse: 1134.6375\n",
      "Epoch 3/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 987.1719 - mse: 987.1719\n",
      "Epoch 4/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 859.8283 - mse: 859.8283\n",
      "Epoch 5/200\n",
      "35/35 [==============================] - 0s 706us/step - loss: 751.2059 - mse: 751.2059\n",
      "Epoch 6/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 658.2194 - mse: 658.2194\n",
      "Epoch 7/200\n",
      "35/35 [==============================] - 0s 706us/step - loss: 578.5511 - mse: 578.5511\n",
      "Epoch 8/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 510.2796 - mse: 510.2796\n",
      "Epoch 9/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 451.7679 - mse: 451.7679\n",
      "Epoch 10/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 401.6077 - mse: 401.6077\n",
      "Epoch 11/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 358.6320 - mse: 358.6320\n",
      "Epoch 12/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 321.8047 - mse: 321.8047\n",
      "Epoch 13/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 290.2360 - mse: 290.2360\n",
      "Epoch 14/200\n",
      "35/35 [==============================] - 0s 765us/step - loss: 263.1792 - mse: 263.1792\n",
      "Epoch 15/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 239.9923 - mse: 239.9923\n",
      "Epoch 16/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 220.1119 - mse: 220.1119\n",
      "Epoch 17/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 203.0716 - mse: 203.0716\n",
      "Epoch 18/200\n",
      "35/35 [==============================] - 0s 559us/step - loss: 188.4634 - mse: 188.4634\n",
      "Epoch 19/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 175.9426 - mse: 175.9426\n",
      "Epoch 20/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 165.2139 - mse: 165.2139\n",
      "Epoch 21/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 156.0167 - mse: 156.0167\n",
      "Epoch 22/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 148.1359 - mse: 148.1359\n",
      "Epoch 23/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 141.3800 - mse: 141.3800\n",
      "Epoch 24/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 135.5906 - mse: 135.5906\n",
      "Epoch 25/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 130.6286 - mse: 130.6286\n",
      "Epoch 26/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 126.3719 - mse: 126.3719\n",
      "Epoch 27/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 122.7243 - mse: 122.7243\n",
      "Epoch 28/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 119.5986 - mse: 119.5986\n",
      "Epoch 29/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 116.9205 - mse: 116.9205\n",
      "Epoch 30/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 114.6231 - mse: 114.6231\n",
      "Epoch 31/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 112.6521 - mse: 112.6521\n",
      "Epoch 32/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 110.9634 - mse: 110.9634\n",
      "Epoch 33/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 109.5154 - mse: 109.5154\n",
      "Epoch 34/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 108.2764 - mse: 108.2764\n",
      "Epoch 35/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 107.2146 - mse: 107.2146\n",
      "Epoch 36/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 106.3032 - mse: 106.3032\n",
      "Epoch 37/200\n",
      "35/35 [==============================] - 0s 559us/step - loss: 105.5221 - mse: 105.5221\n",
      "Epoch 38/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 104.8522 - mse: 104.8522\n",
      "Epoch 39/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 104.2785 - mse: 104.2785\n",
      "Epoch 40/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 103.7861 - mse: 103.7861\n",
      "Epoch 41/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 103.3637 - mse: 103.3637\n",
      "Epoch 42/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 103.0018 - mse: 103.0018\n",
      "Epoch 43/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 102.6924 - mse: 102.6924\n",
      "Epoch 44/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 102.4273 - mse: 102.4273\n",
      "Epoch 45/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 102.1996 - mse: 102.1996\n",
      "Epoch 46/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 102.0041 - mse: 102.0041\n",
      "Epoch 47/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 101.8373 - mse: 101.8373\n",
      "Epoch 48/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 101.6941 - mse: 101.6941\n",
      "Epoch 49/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 101.5713 - mse: 101.5713\n",
      "Epoch 50/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 101.4661 - mse: 101.4661\n",
      "Epoch 51/200\n",
      "35/35 [==============================] - 0s 559us/step - loss: 101.3751 - mse: 101.3751\n",
      "Epoch 52/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 101.2976 - mse: 101.2976\n",
      "Epoch 53/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 101.2301 - mse: 101.2301\n",
      "Epoch 54/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 101.1726 - mse: 101.1726\n",
      "Epoch 55/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 101.1239 - mse: 101.1239\n",
      "Epoch 56/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 101.0815 - mse: 101.0815\n",
      "Epoch 57/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 101.0460 - mse: 101.0460\n",
      "Epoch 58/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 101.0149 - mse: 101.0149\n",
      "Epoch 59/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.9882 - mse: 100.9882\n",
      "Epoch 60/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.9653 - mse: 100.9653\n",
      "Epoch 61/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.9456 - mse: 100.9456\n",
      "Epoch 62/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.9287 - mse: 100.9287\n",
      "Epoch 63/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.9141 - mse: 100.9141\n",
      "Epoch 64/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 100.9012 - mse: 100.9012\n",
      "Epoch 65/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8902 - mse: 100.8902\n",
      "Epoch 66/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 100.8814 - mse: 100.8814\n",
      "Epoch 67/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8728 - mse: 100.8728\n",
      "Epoch 68/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 100.8660 - mse: 100.8660\n",
      "Epoch 69/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8595 - mse: 100.8595\n",
      "Epoch 70/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 100.8542 - mse: 100.8542\n",
      "Epoch 71/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.8495 - mse: 100.8495\n",
      "Epoch 72/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.8457 - mse: 100.8457\n",
      "Epoch 73/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.8413 - mse: 100.8413\n",
      "Epoch 74/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8383 - mse: 100.8383\n",
      "Epoch 75/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 100.8353 - mse: 100.8353\n",
      "Epoch 76/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8333 - mse: 100.8333\n",
      "Epoch 77/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 100.8303 - mse: 100.8303\n",
      "Epoch 78/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8282 - mse: 100.8282\n",
      "Epoch 79/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8261 - mse: 100.8261\n",
      "Epoch 80/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8237 - mse: 100.8237\n",
      "Epoch 81/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 100.8220 - mse: 100.8220\n",
      "Epoch 82/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8199 - mse: 100.8199\n",
      "Epoch 83/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.8184 - mse: 100.8184\n",
      "Epoch 84/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.8166 - mse: 100.8166\n",
      "Epoch 85/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.8147 - mse: 100.8147\n",
      "Epoch 86/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.8132 - mse: 100.8132\n",
      "Epoch 87/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8114 - mse: 100.8114\n",
      "Epoch 88/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.8094 - mse: 100.8094\n",
      "Epoch 89/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.8072 - mse: 100.8072\n",
      "Epoch 90/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.8058 - mse: 100.8058\n",
      "Epoch 91/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.8037 - mse: 100.8037\n",
      "Epoch 92/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.8011 - mse: 100.8011\n",
      "Epoch 93/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.7986 - mse: 100.7986\n",
      "Epoch 94/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.7966 - mse: 100.7966\n",
      "Epoch 95/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.7940 - mse: 100.7940\n",
      "Epoch 96/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.7910 - mse: 100.7910\n",
      "Epoch 97/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.7883 - mse: 100.7883\n",
      "Epoch 98/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.7850 - mse: 100.7850\n",
      "Epoch 99/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.7807 - mse: 100.7807\n",
      "Epoch 100/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.7771 - mse: 100.7771\n",
      "Epoch 101/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.7729 - mse: 100.7729\n",
      "Epoch 102/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 100.7674 - mse: 100.7674\n",
      "Epoch 103/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.7620 - mse: 100.7620\n",
      "Epoch 104/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.7553 - mse: 100.7553\n",
      "Epoch 105/200\n",
      "35/35 [==============================] - 0s 706us/step - loss: 100.7479 - mse: 100.7479\n",
      "Epoch 106/200\n",
      "35/35 [==============================] - 0s 706us/step - loss: 100.7397 - mse: 100.7397\n",
      "Epoch 107/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.7292 - mse: 100.7292\n",
      "Epoch 108/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.7166 - mse: 100.7166\n",
      "Epoch 109/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.7018 - mse: 100.7018\n",
      "Epoch 110/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 100.6834 - mse: 100.6834\n",
      "Epoch 111/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.6598 - mse: 100.6598\n",
      "Epoch 112/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.6264 - mse: 100.6264\n",
      "Epoch 113/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.5760 - mse: 100.5760\n",
      "Epoch 114/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 100.4278 - mse: 100.4278\n",
      "Epoch 115/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 100.2112 - mse: 100.2112\n",
      "Epoch 116/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 99.7424 - mse: 99.7424\n",
      "Epoch 117/200\n",
      "35/35 [==============================] - 0s 706us/step - loss: 97.3389 - mse: 97.3389\n",
      "Epoch 118/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 86.4820 - mse: 86.4820\n",
      "Epoch 119/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 77.5482 - mse: 77.5482\n",
      "Epoch 120/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 75.7876 - mse: 75.7876\n",
      "Epoch 121/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 72.8735 - mse: 72.8735\n",
      "Epoch 122/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 77.0591 - mse: 77.0591\n",
      "Epoch 123/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 72.5016 - mse: 72.5016\n",
      "Epoch 124/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 68.8211 - mse: 68.8211\n",
      "Epoch 125/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 66.4476 - mse: 66.4476\n",
      "Epoch 126/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 64.6084 - mse: 64.6084\n",
      "Epoch 127/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 63.0749 - mse: 63.0749\n",
      "Epoch 128/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 61.7254 - mse: 61.7254\n",
      "Epoch 129/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 60.5242 - mse: 60.5242\n",
      "Epoch 130/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 59.3982 - mse: 59.3982\n",
      "Epoch 131/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 58.5999 - mse: 58.5999\n",
      "Epoch 132/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 57.7176 - mse: 57.7176\n",
      "Epoch 133/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 58.5129 - mse: 58.5129\n",
      "Epoch 134/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 61.1269 - mse: 61.1269\n",
      "Epoch 135/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 57.5422 - mse: 57.5422\n",
      "Epoch 136/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 57.0061 - mse: 57.0061\n",
      "Epoch 137/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 56.4777 - mse: 56.4777\n",
      "Epoch 138/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 55.9875 - mse: 55.9875\n",
      "Epoch 139/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 55.5450 - mse: 55.5450\n",
      "Epoch 140/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 55.1382 - mse: 55.1382\n",
      "Epoch 141/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 54.7456 - mse: 54.7456\n",
      "Epoch 142/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 54.4140 - mse: 54.4140\n",
      "Epoch 143/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 54.0727 - mse: 54.0727\n",
      "Epoch 144/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 53.7816 - mse: 53.7816\n",
      "Epoch 145/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 53.4756 - mse: 53.4756\n",
      "Epoch 146/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 53.2160 - mse: 53.2160\n",
      "Epoch 147/200\n",
      "35/35 [==============================] - 0s 588us/step - loss: 52.9538 - mse: 52.9538\n",
      "Epoch 148/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 52.7554 - mse: 52.7554\n",
      "Epoch 149/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 52.5366 - mse: 52.5366\n",
      "Epoch 150/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 52.3239 - mse: 52.3239\n",
      "Epoch 151/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 52.1554 - mse: 52.1554\n",
      "Epoch 152/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 51.9863 - mse: 51.9863\n",
      "Epoch 153/200\n",
      "35/35 [==============================] - 0s 706us/step - loss: 51.8206 - mse: 51.8206\n",
      "Epoch 154/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 51.6867 - mse: 51.6867\n",
      "Epoch 155/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 51.5389 - mse: 51.5389\n",
      "Epoch 156/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 51.4280 - mse: 51.4280\n",
      "Epoch 157/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 51.2957 - mse: 51.2957\n",
      "Epoch 158/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 51.2037 - mse: 51.2037\n",
      "Epoch 159/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 51.0878 - mse: 51.0878\n",
      "Epoch 160/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.9864 - mse: 50.9864\n",
      "Epoch 161/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 50.9138 - mse: 50.9138\n",
      "Epoch 162/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 50.8455 - mse: 50.8455\n",
      "Epoch 163/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.7458 - mse: 50.7458\n",
      "Epoch 164/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.6754 - mse: 50.6754\n",
      "Epoch 165/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 50.6115 - mse: 50.6115\n",
      "Epoch 166/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.5516 - mse: 50.5516\n",
      "Epoch 167/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.4977 - mse: 50.4977\n",
      "Epoch 168/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 50.4443 - mse: 50.4443\n",
      "Epoch 169/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.4093 - mse: 50.4093\n",
      "Epoch 170/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.3403 - mse: 50.3403\n",
      "Epoch 171/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.3189 - mse: 50.3189\n",
      "Epoch 172/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.2914 - mse: 50.2914\n",
      "Epoch 173/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 50.2432 - mse: 50.2432\n",
      "Epoch 174/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.2133 - mse: 50.2133\n",
      "Epoch 175/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.1791 - mse: 50.1791\n",
      "Epoch 176/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 50.1474 - mse: 50.1474\n",
      "Epoch 177/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 50.1209 - mse: 50.1209\n",
      "Epoch 178/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 50.0755 - mse: 50.0755\n",
      "Epoch 179/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.0425 - mse: 50.0425\n",
      "Epoch 180/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.0365 - mse: 50.0365\n",
      "Epoch 181/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.0105 - mse: 50.0105\n",
      "Epoch 182/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 50.0011 - mse: 50.0011\n",
      "Epoch 183/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 49.9990 - mse: 49.9990\n",
      "Epoch 184/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 49.9605 - mse: 49.9605\n",
      "Epoch 185/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 49.9574 - mse: 49.9574\n",
      "Epoch 186/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 49.9361 - mse: 49.9361\n",
      "Epoch 187/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 49.9196 - mse: 49.9196\n",
      "Epoch 188/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 49.9443 - mse: 49.9443\n",
      "Epoch 189/200\n",
      "35/35 [==============================] - 0s 706us/step - loss: 49.8984 - mse: 49.8984\n",
      "Epoch 190/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 49.8934 - mse: 49.8934\n",
      "Epoch 191/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 49.8775 - mse: 49.8775\n",
      "Epoch 192/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 49.8658 - mse: 49.8658\n",
      "Epoch 193/200\n",
      "35/35 [==============================] - 0s 677us/step - loss: 49.8720 - mse: 49.8720\n",
      "Epoch 194/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 49.8471 - mse: 49.8471\n",
      "Epoch 195/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 49.8432 - mse: 49.8432\n",
      "Epoch 196/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 49.8298 - mse: 49.8298\n",
      "Epoch 197/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 49.8214 - mse: 49.8214\n",
      "Epoch 198/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 49.8364 - mse: 49.8364\n",
      "Epoch 199/200\n",
      "35/35 [==============================] - 0s 618us/step - loss: 49.8235 - mse: 49.8235\n",
      "Epoch 200/200\n",
      "35/35 [==============================] - 0s 647us/step - loss: 49.8141 - mse: 49.8141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1553cd64fa0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 200, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 538us/step - loss: 112.3604 - mse: 112.3604\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mse']\n",
      "[112.36039733886719, 112.36039733886719]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69089f81ed2b007dd37b053b0ecff544931d6f38c1b933baa1b3faccb026f3e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
